{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "                                           Feature Engineering"
      ],
      "metadata": {
        "id": "KhGJOQmQsuIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "` Q1 What is a parameter? `"
      ],
      "metadata": {
        "id": "zXL_L6mJtk5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In programming and mathematics, a parameter is a named variable passed into a function, method, or subroutine. It acts as a placeholder for the actual values (called arguments) that will be supplied when the function is called. Parameters define the type of input a function expects and allow functions to be reusable with different data.\n",
        "\n",
        "For example, in the Python function def calculate_sum(a, b):, a and b are parameters. When you call calculate_sum(5, 10), 5 and 10 are the arguments passed to those parameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "4CYpJJoUtud-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PioeDaVzucWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Q2. What is correlation? `"
      ],
      "metadata": {
        "id": "Crg8lvaQtyM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In statistics, correlation refers to the statistical relationship between two or more variables. It describes the extent to which two variables tend to move together. When two variables are correlated, it means that as one variable changes, the other variable tends to change in a predictable way.\n",
        "\n",
        "There are different types of correlation:\n",
        "\n",
        "1. Positive Correlation: As one variable increases, the other variable also tends to increase (e.g., height and weight).\n",
        "\n",
        "2. Negative Correlation: As one variable increases, the other variable tends to decrease (e.g., hours spent studying and number of errors on a test if studying helps reduce errors).\n",
        "\n",
        "3. No Correlation: There is no consistent relationship between the variables.\n",
        "\n",
        "\n",
        "Correlation is often quantified by a correlation coefficient, such as Pearson's r, which ranges from -1 to +1. A value of +1 indicates a perfect positive correlation, -1 indicates a perfect negative correlation, and 0 indicates no linear correlation.\n",
        "\n"
      ],
      "metadata": {
        "id": "fZ3qDPnquBby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pG7YNEmS1mhx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3244cb0"
      },
      "source": [
        "## Q3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "\n",
        "**Machine Learning (ML)** is a subfield of Artificial Intelligence (AI) that enables a computer system to **learn patterns from data** and make predictions/decisions **without being explicitly programmed** for every rule.\n",
        "\n",
        "### Main components of ML\n",
        "1. **Data**: input examples (features) and sometimes labels (targets).\n",
        "2. **Features (X)**: variables used for prediction.\n",
        "3. **Labels/Target (y)**: output variable (only in supervised learning).\n",
        "4. **Model / Algorithm**: mathematical function that maps input → output (e.g., Linear Regression, Decision Tree).\n",
        "5. **Loss/Objective function**: measures model error (e.g., MSE, Log loss).\n",
        "6. **Optimizer / Learning algorithm**: updates model parameters to minimize loss (e.g., Gradient Descent).\n",
        "7. **Training**: process of learning parameters from training data.\n",
        "8. **Evaluation/Validation**: checking performance using test/validation set.\n",
        "9. **Hyperparameters**: external settings (e.g., learning rate, depth)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xmBDfQO53RLm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95da1ae6"
      },
      "source": [
        "## Q4. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "A **loss value** tells how far a model's prediction is from the actual output.\n",
        "\n",
        "- **Lower loss** ⇒ predictions are closer to actual values ⇒ model is better.\n",
        "- **Higher loss** ⇒ model is making larger errors.\n",
        "\n",
        "### Important notes\n",
        "- We compare loss on **training set** and **validation/test set**\n",
        "- If **training loss low but validation loss high** ⇒ **overfitting**\n",
        "- If **both losses high** ⇒ **underfitting** or poor features/model.\n",
        "\n",
        "Example:\n",
        "- Regression uses **MSE / MAE**\n",
        "- Classification uses **Log Loss / Cross Entropy**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wo-AtUuw3YLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "V9Jy1DnQ3YoI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a40aa19"
      },
      "source": [
        "## Q5. What are continuous and categorical variables?\n",
        "\n",
        "### Continuous variables\n",
        "Numeric values with infinite possibilities in a range.\n",
        "Examples:\n",
        "- height, weight, temperature, income\n",
        "\n",
        "### Categorical variables\n",
        "Represent categories/labels.\n",
        "Examples:\n",
        "- gender (Male/Female)\n",
        "- color (Red/Blue/Green)\n",
        "- city (Kolkata/Delhi/Mumbai)\n",
        "\n",
        "Categorical types:\n",
        "- **Nominal**: no order (e.g., city)\n",
        "- **Ordinal**: ordered (e.g., low < medium < high)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zVR3JNGx3cQA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89ebc392"
      },
      "source": [
        "## Q6. How do we handle categorical variables in ML? What are the common techniques?\n",
        "\n",
        "ML models require numeric input, so categorical variables must be encoded.\n",
        "\n",
        "### Common techniques\n",
        "1. **Label Encoding**\n",
        "   - Convert categories into numbers.\n",
        "   - Good for **ordinal categories**.\n",
        "2. **One-Hot Encoding**\n",
        "   - Creates binary columns for each category.\n",
        "   - Best for **nominal categories**.\n",
        "3. **Ordinal Encoding**\n",
        "   - Assign ordered ranks to ordered categories.\n",
        "4. **Target Encoding**\n",
        "   - Replace category with mean of target for that category.\n",
        "   - Useful when many categories (high cardinality).\n",
        "5. **Frequency/Count Encoding**\n",
        "   - Replace category with its frequency."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "29dSMDvc3a9Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fef8f438"
      },
      "source": [
        "## Q7. What do you mean by training and testing a dataset?\n",
        "\n",
        "- **Training dataset**: used to **fit/learn** the model parameters.\n",
        "- **Testing dataset**: used to **evaluate** the trained model performance on unseen data.\n",
        "\n",
        "Goal:\n",
        "- Ensure the model **generalizes** (works well on new/unseen data)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TrwtomFF3dYh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0970ca69"
      },
      "source": [
        "## Q8. What is sklearn.preprocessing?\n",
        "\n",
        "`sklearn.preprocessing` is a module in **Scikit-learn** that provides tools for:\n",
        "\n",
        "- **Scaling**: StandardScaler, MinMaxScaler, RobustScaler\n",
        "- **Normalization**: Normalizer\n",
        "- **Encoding**: OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
        "- **Binarization** and other transformations\n",
        "\n",
        "It helps in preparing data before training ML models."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "KowEGHxO3eFx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95d10de4"
      },
      "source": [
        "## Q9. What is a Test set?\n",
        "\n",
        "A **test set** is a portion of the dataset kept separate from training and used **only for final evaluation**.\n",
        "\n",
        "Why?\n",
        "- To estimate real-world performance\n",
        "- To detect overfitting\n",
        "\n",
        "Common split ratios:\n",
        "- 70/30, 80/20, 75/25"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "QVtnW93w3eyZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80a9dab1"
      },
      "source": [
        "## Q10. How do we split data for model fitting (training and testing) in Python?\n",
        "\n",
        "We use `train_test_split()` from `sklearn.model_selection`.\n",
        "\n",
        "Example:\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SYiE3q5O3fj6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b29b729d"
      },
      "source": [
        "## Q11. How do you approach a Machine Learning problem?\n",
        "\n",
        "Typical ML workflow:\n",
        "1. **Problem understanding** (classification/regression/clustering)\n",
        "2. **Collect data**\n",
        "3. **Data cleaning** (missing values, outliers)\n",
        "4. **EDA (Exploratory Data Analysis)**\n",
        "5. **Feature engineering**\n",
        "6. **Split data** into train/test (and validation)\n",
        "7. **Model selection**\n",
        "8. **Train model**\n",
        "9. **Evaluate** using metrics\n",
        "10. **Hyperparameter tuning**\n",
        "11. **Deploy / monitoring**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "BeNxrOOG3gO6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b2be44a"
      },
      "source": [
        "## Q12. Why do we have to perform EDA before fitting a model?\n",
        "\n",
        "EDA helps:\n",
        "- Understand data distribution\n",
        "- Detect missing values/outliers\n",
        "- Identify relationships between variables\n",
        "- Choose correct preprocessing methods\n",
        "- Improve feature selection/engineering\n",
        "\n",
        "Without EDA:\n",
        "- Model accuracy may suffer due to poor quality data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9AT7oKmH3gye"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daf94fe4"
      },
      "source": [
        "## Q13. What is correlation?\n",
        "\n",
        "**Correlation** measures the strength and direction of relationship between two variables.\n",
        "\n",
        "- Range: **-1 to +1**\n",
        "- +1: perfect positive correlation\n",
        "- 0: no correlation\n",
        "- -1: perfect negative correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "aHnLrTPt3hb6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "692b8c91"
      },
      "source": [
        "## Q14. What does negative correlation mean?\n",
        "\n",
        "**Negative correlation** means:\n",
        "- when one variable increases, the other decreases.\n",
        "\n",
        "Example:\n",
        "- as price increases, demand decreases (often)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "roFABri83iAK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4be693a"
      },
      "source": [
        "## Q15. How can you find correlation between variables in Python?\n",
        "\n",
        "Using Pandas:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df.corr()\n",
        "```\n",
        "\n",
        "To visualize:\n",
        "- `seaborn.heatmap(df.corr())` (if seaborn available)\n",
        "or matplotlib-based heatmap."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MwPUHHQy3ipS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c5cc139"
      },
      "source": [
        "## Q16. What is causation? Explain difference between correlation and causation with an example.\n",
        "\n",
        "### Causation\n",
        "One variable **directly affects** the other.\n",
        "\n",
        "### Correlation\n",
        "Variables change together but may not have a cause-effect relation.\n",
        "\n",
        "Example:\n",
        "- Ice cream sales and drowning cases may be correlated (both increase in summer).\n",
        "- But ice cream does **not** cause drowning → **correlation ≠ causation**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "L7z14h8h3jNi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f0f8a71"
      },
      "source": [
        "## Q17. What is an optimizer? What are different types of optimizers? Explain each with example.\n",
        "\n",
        "An **optimizer** updates model parameters to minimize the loss function.\n",
        "\n",
        "### Common optimizers\n",
        "1. **Gradient Descent (Batch GD)**\n",
        "   - uses all data at once\n",
        "2. **Stochastic Gradient Descent (SGD)**\n",
        "   - updates using one sample\n",
        "3. **Mini-batch Gradient Descent**\n",
        "   - updates using small batches\n",
        "4. **Adam**\n",
        "   - adaptive learning rate + momentum\n",
        "5. **RMSprop**\n",
        "   - adaptive learning rate\n",
        "6. **Adagrad**\n",
        "   - adapts learning rate for each parameter\n",
        "\n",
        "In sklearn models like LinearRegression, the optimizer is internal (closed-form or iterative depending on estimator)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "G0SuySah3jwC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c76b4e47"
      },
      "source": [
        "## Q18. What is sklearn.linear_model?\n",
        "\n",
        "`sklearn.linear_model` is a Scikit-learn module that provides **linear models** such as:\n",
        "\n",
        "- LinearRegression\n",
        "- Ridge, Lasso, ElasticNet\n",
        "- LogisticRegression\n",
        "- SGDRegressor / SGDClassifier\n",
        "- Perceptron\n",
        "\n",
        "Used for regression and classification."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DFDCwNNO3kSb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28e83e57"
      },
      "source": [
        "## Q19. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "`model.fit()` trains the model on data.\n",
        "\n",
        "Basic syntax:\n",
        "```python\n",
        "model.fit(X_train, y_train)\n",
        "```\n",
        "\n",
        "### Arguments\n",
        "- `X_train`: feature matrix (2D)\n",
        "- `y_train`: target vector (1D)\n",
        "\n",
        "Some models accept extra params, but these two are mandatory in supervised learning."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NozpONEb3k07"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b272913"
      },
      "source": [
        "## Q20. What does model.predict() do? What arguments must be given?\n",
        "\n",
        "`model.predict()` generates predictions using a trained model.\n",
        "\n",
        "Syntax:\n",
        "```python\n",
        "y_pred = model.predict(X_test)\n",
        "```\n",
        "\n",
        "### Argument\n",
        "- `X_test`: feature matrix for which predictions are needed."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TKcVjRT93lhS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79e95b58"
      },
      "source": [
        "## Q21. What are continuous and categorical variables?\n",
        "\n",
        "\n",
        "Continuous = numeric measurable values (e.g., salary, height).  \n",
        "Categorical = label-based values (e.g., city, gender)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "beOrEfT13mG7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04c3ee15"
      },
      "source": [
        "## Q22. What is feature scaling? How does it help in ML?\n",
        "\n",
        "**Feature scaling** converts features to similar ranges.\n",
        "\n",
        "Why needed?\n",
        "- Many models depend on distance or gradient:\n",
        "  - KNN, KMeans, SVM, Logistic Regression, Neural Networks\n",
        "- Improves convergence speed and stability\n",
        "\n",
        "Common scaling:\n",
        "- Standardization (mean=0, std=1)\n",
        "- Min-Max scaling (0 to 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8nBZLU7P3mk7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "836bd76c"
      },
      "source": [
        "## Q23. How do we perform scaling in Python?\n",
        "\n",
        "Using Scikit-learn scalers:\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "698i102s3nHC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "885fb5ce"
      },
      "source": [
        "## Q24. What is sklearn.preprocessing?\n",
        "\n",
        "\n",
        "It contains preprocessing tools like:\n",
        "- StandardScaler, MinMaxScaler\n",
        "- OneHotEncoder, LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Lu16v4rb3ntr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42e2f287"
      },
      "source": [
        "## Q25. Explain data encoding.\n",
        "\n",
        "**Data encoding** converts categorical text features into numeric form.\n",
        "\n",
        "Examples:\n",
        "- Label Encoding: A,B,C → 0,1,2\n",
        "- OneHot Encoding: Color=Red/Blue → [1,0] / [0,1]\n",
        "\n",
        "Encoding is required because most ML algorithms cannot directly work with strings."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IeiBGZWJ3oMz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f326e53"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ✅ Practical Examples in Python\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "df = pd.DataFrame({\n",
        "    \"Age\": [22, 25, 47, 52, 46, 56],\n",
        "    \"Salary\": [25000, 32000, 58000, 60000, 52000, 62000],\n",
        "    \"City\": [\"Kolkata\", \"Delhi\", \"Kolkata\", \"Mumbai\", \"Delhi\", \"Mumbai\"],\n",
        "    \"Purchased\": [0, 1, 0, 1, 1, 1]\n",
        "})\n",
        "\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f426a75"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train-Test Split example\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[[\"Age\", \"Salary\"]]\n",
        "y = df[\"Purchased\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.33, random_state=42\n",
        ")\n",
        "\n",
        "X_train, X_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f442037"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Feature scaling example\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled[:3], X_test_scaled[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "089c8994"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Encoding categorical variables example (OneHotEncoding)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "city_encoded = encoder.fit_transform(df[[\"City\"]])\n",
        "\n",
        "encoded_df = pd.DataFrame(city_encoded, columns=encoder.get_feature_names_out([\"City\"]))\n",
        "encoded_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "798eab51"
      },
      "outputs": [],
      "source": [
        "\n",
        "# model.fit() and model.predict() example (Logistic Regression)\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy, y_pred\n"
      ]
    }
  ]
}